# Reinforcement Learning

## 1. Methods

### (1) Value based: Learn Q function

Generalized Policy Iteration: In GPI, the value function becomes close to the true value under current policy. At the same time, the policy becomes closer to the optimality.

![GPI](/Users/txh/Desktop/实习/Preparation/GPI.png)

对值函数取argmax生成Pi(s)，对于value based的方法，都是采用这样的策略来求得action

##### 特性

​		1) Value based 方法只适合离散的action情况，因为要取argmax_a Q(s,a)

​		2)  Value based 方法只适合 deterministic policy (确定性策略) 的情况

### (2) Policy based: Learn Policy

**Policy based**: maximize the expected return by optimizing policy

**On-policy**: means you need to learn from trajectories generated by the current policy

##### Classical way: Policy gradient

Loss : $$-log(\pi(a_t|s_t))\cdot r_t$$，when the probability of an action is small but the reward is large the loss would be large



## 2. Classic algorithms

​	(1) TRPO / PPO

​	(2) DDPG

​	(3) DQN

## 3. Algorithm

(1) Importance sampling